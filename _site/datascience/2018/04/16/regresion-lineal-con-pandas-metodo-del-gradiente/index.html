<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Regresión Lineal con Pandas: método del gradiente</title>
  <link rel='shortcut icon' type='image/png' href='/favicon.png' />
  <meta name="description" content="Curso de aprendizaje automático de Coursera">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://piensapython.com/datascience/2018/04/16/regresion-lineal-con-pandas-metodo-del-gradiente/">
  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-96907641-1', 'auto');
  ga('send', 'pageview');

</script>
  

  
  
    <!--
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
    <script type="text/x-mathjax-config">
	    MathJax.Hub.Config({
		    TeX: { equationNumbers: { autoNumber: "AMS" } }
	    });
    </script>
    -->
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML">
    </script>
  
  <style>
    .table {
      border-collapse: collapse;
      text-align: center;
    }
    .table, th, td {
      border: 1px solid black;
    }
  </style>
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">Python y la Ciencia de Datos</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
          <a class="page-link" href="/acerca/">Acerca</a>
          
        
          
          <a class="page-link" href="/ciencia-de-datos/">Ciencia de Datos</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/python/">Python</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Regresión Lineal con Pandas: método del gradiente</h1>
    <p class="post-meta"><time datetime="2018-04-16T00:06:00-05:00" itemprop="datePublished">Apr 16, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <div class="foto-center" align="center">
  <img src="/imagenes/ng_machine_learn.png" alt="curso de aprendizaje automatico de coursera" />
  <figcaption>Curso de aprendizaje automático de Coursera</figcaption>
</div>

<p>El curso de aprendizaje automático (machine learning) de <a href="https://www.coursera.org/learn/machine-learning">Andrew Ng en Coursera</a> es muy popular y
es una buena introducción a este tema. En su curso, Ng recomienda usar Matlab u Octave para los ejercicios de programación. Uno
de estos ejercicios pide hallar la curva de ajuste lineal de una serie de datos.</p>

<blockquote>
In this exercise, you will implement linear regression and get to see it work
on data.  Before starting on this programming exercise, we strongly recommend
watching the video lectures and completing the review questions for
the associated topics.
To get started with the exercise, you will need to download the starter
code and unzip its contents to the directory where you wish to complete the
exercise.  If needed, use the cd command in Octave/MATLAB to change to
this directory before starting this exercise.
You can also find instructions for installing Octave/MATLAB in the “Environment
Setup Instructions” of the course website.
</blockquote>

<p>El método del gradiente (<em>gradient descent</em> en inglés) en regresión lineal permite obtener
la curva de ajuste de una función de forma iterativa minimizando la función costo:</p>

<script type="math/tex; mode=display">J(\theta) = \frac{1}{2m}\sum_{i=1}^mh_{\theta}((x^{(i)}) - y^{(i)})^{2}</script>

<p>La hipótesis <script type="math/tex">h_{\theta}(x)</script> está dada por el modelo lineal:</p>

<script type="math/tex; mode=display">h_{\theta}(x) = \theta^{T}x = \theta_{0} + \theta_{1}x_{1}</script>

<p>El ajuste se logra cambiando los valores <script type="math/tex">\theta_{j}</script> con el método del gradiente en el
que en cada iteración se actualiza ese valor:</p>

<script type="math/tex; mode=display">\theta_{j} := \theta_{j} - \alpha \frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}</script>

<p>Donde <script type="math/tex">\alpha</script> es la tasa de aprendizaje. A continuación se muestra la implementación de este
método usando los módulos pandas y numpy de python y la visualización con matplotlib.</p>

<p>El algoritmo que se usa queda de la siguiente forma para theta0 y theta1: repetir hasta que se alcance convergencia</p>

<script type="math/tex; mode=display">\theta_{0} := \theta_{0} - \alpha \frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})</script>

<script type="math/tex; mode=display">\theta_{1} := \theta_{1} - \alpha \frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x^{(i)}</script>

<p>El archivo con los datos se puede ver aquí: <a href="https://github.com/leonardo384/MachineLearningCoursera/blob/master/ex1data1.txt">ex1data1.txt</a></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># Implementación del método del gradiente con pandas</span>
<span class="c"># Datos del curso de Andrew Ng de aprendizaje automático</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">archivo</span> <span class="o">=</span> <span class="s">'ex1data1.txt'</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">archivo</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">'poblacion'</span><span class="p">,</span> <span class="s">'ganancia'</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">poblacion</span>     <span class="n">ganancia</span>
<span class="mi">0</span>  <span class="mf">6.1101</span>  <span class="mf">17.5920</span>
<span class="mi">1</span>  <span class="mf">5.5277</span>   <span class="mf">9.1302</span>
<span class="mi">2</span>  <span class="mf">8.5186</span>  <span class="mf">13.6620</span>
<span class="mi">3</span>  <span class="mf">7.0032</span>  <span class="mf">11.8540</span>
<span class="mi">4</span>  <span class="mf">5.8598</span>   <span class="mf">6.8233</span>

<span class="k">def</span> <span class="nf">calc_costo</span><span class="p">(</span><span class="n">dframe</span><span class="p">,</span> <span class="n">th0</span><span class="p">,</span> <span class="n">th1</span><span class="p">):</span>
    <span class="s">""" Calcula el costo J """</span>
    <span class="n">poblacion</span> <span class="o">=</span> <span class="n">dframe</span><span class="p">[</span><span class="s">'poblacion'</span><span class="p">]</span>
    <span class="n">prediccion</span> <span class="o">=</span> <span class="n">poblacion</span> <span class="o">*</span> <span class="n">th1</span> <span class="o">+</span> <span class="n">th0</span>
    <span class="n">ganancia</span> <span class="o">=</span> <span class="n">dframe</span><span class="p">[</span><span class="s">'ganancia'</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">((</span><span class="n">prediccion</span> <span class="o">-</span> <span class="n">ganancia</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dframe</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>

<span class="k">def</span> <span class="nf">grad_desc</span><span class="p">(</span><span class="n">dframe</span><span class="p">,</span> <span class="n">th0</span><span class="p">,</span> <span class="n">th1</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="s">""" Implementa un paso en el algoritmo de descenso en gradiente """</span>
    <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dframe</span><span class="p">)</span>
    <span class="n">dframe</span><span class="p">[</span><span class="s">'prediccion'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dframe</span><span class="p">[</span><span class="s">'poblacion'</span><span class="p">]</span> <span class="o">*</span> <span class="n">th1</span> <span class="o">+</span> <span class="n">th0</span>
    <span class="n">th0</span> <span class="o">=</span> <span class="n">th0</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">length</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">dframe</span><span class="p">[</span><span class="s">'prediccion'</span><span class="p">]</span> <span class="o">-</span> <span class="n">dframe</span><span class="p">[</span><span class="s">'ganancia'</span><span class="p">]))</span>
    <span class="n">th1</span> <span class="o">=</span> <span class="n">th1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">length</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(((</span><span class="n">dframe</span><span class="p">[</span><span class="s">'prediccion'</span><span class="p">]</span> <span class="o">-</span> <span class="n">dframe</span><span class="p">[</span><span class="s">'ganancia'</span><span class="p">])</span> <span class="o">*</span> <span class="n">dframe</span><span class="p">[</span><span class="s">'poblacion'</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">th0</span><span class="p">,</span> <span class="n">th1</span></code></pre></figure>

<p>Implementación y gráfica luego de 200 iteraciones:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">test_graph</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">iteraciones</span><span class="p">):</span>
    <span class="s">""" implementa el método del descenso en el dataframe """</span>
    <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteraciones</span><span class="p">):</span>
        <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span> <span class="o">=</span> <span class="n">grad_desc</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

    <span class="n">costo</span> <span class="o">=</span> <span class="n">calc_costo</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'poblacion'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'ganancia'</span><span class="p">],</span> <span class="s">'b.'</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'poblacion'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'poblacion'</span><span class="p">]</span><span class="o">*</span><span class="n">theta1</span> <span class="o">+</span> <span class="n">theta0</span><span class="p">,</span> <span class="s">'r-'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Método del gradiente con pandas'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Población'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Ganancia'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="s">'Costo: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">costo</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="s">'theta0: {}</span><span class="se">\n</span><span class="s">theta1: {}</span><span class="se">\n</span><span class="s">iteraciones: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span><span class="p">,</span> <span class="n">iteraciones</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">test_graph</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span></code></pre></figure>

<div class="foto-center" align="center">
  <img src="/imagenes/figure_1_grad_desc.png" alt="grafica de la curva de ajuste" />
  <figcaption>Ajuste aproximado de curva para 200 iteraciones</figcaption>
</div>

<p>Graficamos la función costo al avanzar el número de iteraciones para observar como se va acercando
a un valor mínimo:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">plot_with_cost</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">iteraciones</span><span class="p">):</span>
    <span class="s">""" Calcula el costo por cada iteración """</span>
    <span class="n">valores_costo</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteraciones</span><span class="p">):</span>
        <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span> <span class="o">=</span> <span class="n">grad_desc</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="n">costo</span> <span class="o">=</span> <span class="n">calc_costo</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span><span class="p">)</span>
        <span class="n">valores_costo</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">costo</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">iteraciones</span><span class="p">),</span> <span class="n">valores_costo</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_with_cost</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">1500</span><span class="p">)</span></code></pre></figure>

<p>Y esta es la gráfica del cambio del costo a medida que transcurren las iteraciones:</p>

<div class="foto-center" align="center">
  <img src="/imagenes/figure_2_costo_grad_desc.png" alt="grafico de la funcion costo" />
  <figcaption>Cambio en el costo de la función J</figcaption>
</div>

<p>Según la gráfica se necesitan cerca de 1500 iteraciones para hallar un ajuste óptimo. Usando ese
valor obtenemos una mejor gráfica de la función lineal que se ajusta a los datos:</p>

<div class="foto-center" align="center">
  <img src="/imagenes/figure_3_grad_desc.png" alt="grafica de la curva de ajuste" />
  <figcaption>Curva de ajuste luego de 1500 iteraciones</figcaption>
</div>

<p>Finalmente podemos ver la evolución de la curva de ajuste y de la función costo 
a medida que se ejecutan las iteraciones:</p>

<div class="foto-center" align="center">
  <img src="/imagenes/figure_4_multiple_plots.png" alt="graficas multiples" />
  <figcaption>Cambios luego de diferentes iteraciones</figcaption>
</div>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Python y la Ciencia de Datos</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Python y la Ciencia de Datos
            
            </li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          

          
          <li>
            <a href="https://twitter.com/Pythonista100"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">Pythonista100</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Este blog está dedicado al lenguaje de programación Python y sus aplicaciones en la Ciencia de Datos
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
